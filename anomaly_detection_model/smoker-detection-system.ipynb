{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11144034,"sourceType":"datasetVersion","datasetId":6951708}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Smoking Detection YOLOv8 Notebook for Kaggle","metadata":{}},{"cell_type":"code","source":"# Install required libraries\n!pip install ultralytics opencv-python roboflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T07:28:40.422328Z","iopub.execute_input":"2025-03-25T07:28:40.422656Z","iopub.status.idle":"2025-03-25T07:28:46.905278Z","shell.execute_reply.started":"2025-03-25T07:28:40.422636Z","shell.execute_reply":"2025-03-25T07:28:46.904383Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.96-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nCollecting roboflow\n  Downloading roboflow-1.1.58-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2025.1.31)\nCollecting idna==3.7 (from roboflow)\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\nCollecting pillow-heif>=0.18.0 (from roboflow)\n  Downloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.9.0.post0)\nCollecting python-dotenv (from roboflow)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.17.0)\nRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.3.0)\nRequirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.96-py3-none-any.whl (949 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading roboflow-1.1.58-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: filetype, python-dotenv, pillow-heif, idna, ultralytics-thop, ultralytics, roboflow\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed filetype-1.2.0 idna-3.7 pillow-heif-0.22.0 python-dotenv-1.0.1 roboflow-1.1.58 ultralytics-8.3.96 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport cv2\nimport numpy as np\nimport torch\nfrom ultralytics import YOLO\nimport time\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\n# Training function optimized for Kaggle\ndef train_yolov8_model(data_yaml_path, output_dir='/kaggle/working/runs', \n                       epochs=50, imgsz=640, batch_size=16):\n    \"\"\"\n    Train YOLOv8 model for smoking detection on Kaggle\n    \n    Args:\n        data_yaml_path: Path to data.yaml file\n        output_dir: Directory to save training outputs\n        epochs: Number of training epochs\n        imgsz: Image size for training\n        batch_size: Batch size for training\n    \n    Returns:\n        Path to trained model\n    \"\"\"\n    print(f\"Starting training with data config: {data_yaml_path}\")\n    \n    # Ensure output directory exists\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Create YOLOv8 model - using small variant for balanced performance\n    model = YOLO('yolov8s.pt')\n    \n    # Train the model\n    results = model.train(\n        data=data_yaml_path,\n        epochs=epochs,\n        imgsz=imgsz,\n        batch=batch_size,\n        name='smoking_detection_model',\n        project=output_dir,\n        patience=10,  # Early stopping patience\n        device='0' if torch.cuda.is_available() else 'cpu'\n    )\n    \n    # Get the path to the best model\n    best_model_path = model.best\n    print(f\"Training complete. Best model saved at: {best_model_path}\")\n    \n    return best_model_path\n\n# Evaluation function\ndef evaluate_model(model_path, data_yaml_path):\n    \"\"\"\n    Evaluate trained model on test dataset\n    \n    Args:\n        model_path: Path to trained model\n        data_yaml_path: Path to data.yaml file\n    \n    Returns:\n        Evaluation metrics\n    \"\"\"\n    print(f\"Evaluating model: {model_path}\")\n    \n    # Load the model\n    model = YOLO(model_path)\n    \n    # Run evaluation\n    metrics = model.val(data=data_yaml_path, split='test')\n    \n    # Create a visualization of metrics\n    plt.figure(figsize=(10, 6))\n    plt.title(\"Model Performance Metrics\")\n    \n    # Plotting key metrics\n    metrics_data = [\n        metrics.box.map,   # mAP50-95\n        metrics.box.map50, # mAP50\n        metrics.box.p,     # Precision\n        metrics.box.r      # Recall\n    ]\n    metric_names = ['mAP50-95', 'mAP50', 'Precision', 'Recall']\n    \n    plt.bar(metric_names, metrics_data)\n    plt.ylabel('Score')\n    plt.ylim(0, 1)\n    \n    # Save the plot\n    plt.savefig('/kaggle/working/model_metrics.png')\n    plt.close()\n    \n    print(\"\\nEvaluation Metrics:\")\n    print(f\"mAP50-95: {metrics.box.map}\")\n    print(f\"mAP50: {metrics.box.map50}\")\n    print(f\"Precision: {metrics.box.p}\")\n    print(f\"Recall: {metrics.box.r}\")\n    \n    return metrics\n\n# Visualization of training results\ndef visualize_training_results(runs_dir='/kaggle/working/runs'):\n    \"\"\"\n    Visualize training results from YOLO output\n    \n    Args:\n        runs_dir: Directory containing training runs\n    \"\"\"\n    # Find the latest training run\n    import glob\n    import shutil\n    \n    # Find all training result directories\n    result_dirs = glob.glob(os.path.join(runs_dir, 'smoking_detection_model*'))\n    \n    if not result_dirs:\n        print(\"No training results found.\")\n        return\n    \n    # Get the latest run\n    latest_run = max(result_dirs, key=os.path.getmtime)\n    \n    # Copy key visualization files to working directory\n    results_files = [\n        'results.png',\n        'confusion_matrix.png',\n        'val_batch0_pred.jpg'\n    ]\n    \n    for filename in results_files:\n        src_path = os.path.join(latest_run, filename)\n        dest_path = os.path.join('/kaggle/working', filename)\n        \n        if os.path.exists(src_path):\n            shutil.copy(src_path, dest_path)\n            print(f\"Copied {filename} to working directory\")\n        else:\n            print(f\"{filename} not found in training results\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T07:32:47.694798Z","iopub.execute_input":"2025-03-25T07:32:47.695205Z","iopub.status.idle":"2025-03-25T07:32:51.873413Z","shell.execute_reply.started":"2025-03-25T07:32:47.695174Z","shell.execute_reply":"2025-03-25T07:32:51.872749Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Main execution function for Kaggle\ndef main():\n    # Check GPU availability\n    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n    print(f\"Current Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n    \n    # Set the path to the dataset\n    dataset_path = '/kaggle/input/smoking-person-detection'\n    \n    # Find the data.yaml file\n    data_yaml_path = os.path.join(dataset_path, 'data.yaml')\n    \n    if not os.path.exists(data_yaml_path):\n        print(f\"data.yaml not found at {data_yaml_path}\")\n        return\n    \n    # Print dataset details\n    print(f\"Using dataset from: {dataset_path}\")\n    print(f\"Data configuration file: {data_yaml_path}\")\n    \n    # Verify dataset contents\n    print(\"\\nDataset Contents:\")\n    print(\"Training images:\", len(os.listdir(os.path.join(dataset_path, 'train', 'images'))))\n    print(\"Validation images:\", len(os.listdir(os.path.join(dataset_path, 'valid', 'images'))))\n    print(\"Test images:\", len(os.listdir(os.path.join(dataset_path, 'test', 'images'))))\n    \n    # Train the model\n    best_model_path = train_yolov8_model(data_yaml_path)\n    \n    # Evaluate the model\n    evaluate_model(best_model_path, data_yaml_path)\n    \n    # Visualize training results\n    visualize_training_results()\n    \n    print(\"Training and evaluation complete!\")\n\n# Run the main function\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T07:33:17.052247Z","iopub.execute_input":"2025-03-25T07:33:17.052863Z","iopub.status.idle":"2025-03-25T07:56:35.060504Z","shell.execute_reply.started":"2025-03-25T07:33:17.052823Z","shell.execute_reply":"2025-03-25T07:56:35.059058Z"}},"outputs":[{"name":"stdout","text":"CUDA Available: True\nCurrent Device: Tesla P100-PCIE-16GB\nUsing dataset from: /kaggle/input/smoking-person-detection\nData configuration file: /kaggle/input/smoking-person-detection/data.yaml\n\nDataset Contents:\nTraining images: 2058\nValidation images: 195\nTest images: 96\nStarting training with data config: /kaggle/input/smoking-person-detection/data.yaml\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 312MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/input/smoking-person-detection/data.yaml, epochs=50, time=None, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=/kaggle/working/runs, name=smoking_detection_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/kaggle/working/runs/smoking_detection_model\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 43.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \nModel summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n\nTransferred 349/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /kaggle/working/runs/smoking_detection_model', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 146MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/smoking-person-detection/train/labels... 2058 images, 18 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2058/2058 [00:06<00:00, 309.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/smoking-person-detection/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/smoking-person-detection/valid/labels... 195 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [00:00<00:00, 214.23it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/smoking-person-detection/valid is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to /kaggle/working/runs/smoking_detection_model/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/smoking_detection_model\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/50      4.32G      1.657      1.869        1.8         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:40<00:00,  3.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.33it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.463      0.456      0.436      0.149\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/50      4.32G      1.631      1.499      1.755         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:39<00:00,  3.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.45it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.645      0.456      0.482      0.169\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/50      4.33G      1.617      1.508      1.749         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.471      0.494      0.478      0.165\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/50      4.33G      1.601       1.45      1.716         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.45it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.492      0.518      0.465      0.162\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/50      4.33G      1.509      1.322      1.643         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.47it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.495      0.607      0.547      0.202\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/50      4.33G      1.478      1.268      1.619         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.535       0.57      0.559      0.201\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/50      4.33G      1.433      1.208       1.59         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.597      0.618      0.582      0.223\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/50      4.33G      1.405      1.167      1.568         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.574      0.599      0.582      0.226\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/50      4.33G       1.36       1.09      1.518         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.46it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.535      0.567      0.505      0.156\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/50      4.33G      1.338      1.084      1.511         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.72it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.632      0.651      0.649      0.232\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/50      4.33G      1.306      1.042      1.486         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.659      0.666      0.644      0.275\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/50      4.33G      1.303      1.024      1.486         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.65it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.625       0.65      0.652      0.274\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/50      4.33G      1.293      1.011      1.471         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.612      0.641      0.637      0.266\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/50      4.33G      1.256     0.9587      1.439         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.647      0.675      0.623      0.238\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/50      4.33G      1.214     0.9338      1.418         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.59it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.659      0.684      0.672      0.274\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/50      4.33G        1.2      0.904      1.404         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.50it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.686      0.666      0.659      0.253\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/50      4.33G      1.185     0.9064      1.395         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.60it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.636      0.629        0.6      0.229\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/50      4.33G      1.166     0.8842      1.384         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.683      0.679      0.656      0.248\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/50      4.33G      1.155     0.8626      1.373         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.42it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.743      0.708      0.715      0.267\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/50      4.33G      1.141     0.8359      1.358         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.714      0.722      0.704        0.3\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      21/50      4.33G       1.12     0.8187      1.351         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.715      0.697       0.71       0.29\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      22/50      4.33G      1.099     0.8013       1.33         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419       0.65      0.681      0.661      0.276\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      23/50      4.33G      1.088     0.7804      1.316         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.62it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.724      0.721      0.704      0.306\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      24/50      4.33G      1.078     0.7809      1.318         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.67it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.719      0.701      0.696       0.28\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      25/50      4.33G      1.053     0.7648      1.298         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.733       0.69      0.692      0.287\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      26/50      4.33G      1.032     0.7392      1.287         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.723      0.701      0.672      0.278\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      27/50      4.33G      1.016     0.7292      1.273         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.64it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.743      0.677      0.669      0.259\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      28/50      4.33G      1.009     0.7122      1.274         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.39it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.703      0.696      0.685      0.282\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      29/50      4.33G     0.9956     0.6934      1.259         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.63it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.745       0.72      0.734      0.303\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      30/50      4.33G     0.9875     0.6902      1.264         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.72it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.781      0.702      0.717      0.296\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      31/50      4.33G     0.9871     0.6837      1.251         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.756      0.713      0.717      0.298\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      32/50      4.33G     0.9617     0.6737      1.238         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.759      0.714      0.723      0.297\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      33/50      4.33G     0.9433     0.6525      1.229         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:38<00:00,  3.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.772      0.699      0.714      0.302\n\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 23, best model saved as best.pt.\nTo update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n33 epochs completed in 0.376 hours.\nOptimizer stripped from /kaggle/working/runs/smoking_detection_model/weights/last.pt, 22.5MB\nOptimizer stripped from /kaggle/working/runs/smoking_detection_model/weights/best.pt, 22.5MB\n\nValidating /kaggle/working/runs/smoking_detection_model/weights/best.pt...\nUltralytics 8.3.96 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        195        419      0.726      0.721      0.704      0.306\n                person        190        216      0.846      0.875      0.891      0.456\n                 smoke        193        203      0.606      0.567      0.517      0.155\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.2ms preprocess, 4.5ms inference, 0.0ms loss, 4.0ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/smoking_detection_model\u001b[0m\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-c46aa081175a>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-c46aa081175a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_yolov8_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_yaml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-68e75fbcb639>\u001b[0m in \u001b[0;36mtrain_yolov8_model\u001b[0;34m(data_yaml_path, output_dir, epochs, imgsz, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Get the path to the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training complete. Best model saved at: {best_model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Access model.names attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \"\"\"\n\u001b[0;32m-> 1156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"model\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'DetectionModel' object has no attribute 'best'"],"ename":"AttributeError","evalue":"'DetectionModel' object has no attribute 'best'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"import shutil\n\n# Define source directory and output zip file\nsource_dir = \"/kaggle/working/runs\"\noutput_zip = \"/kaggle/working/output_run_evaluations.zip\"\n\n# Create zip archive of the working directory\nshutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', source_dir)\n\nprint(f\"Zipped all contents of {source_dir} into {output_zip}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T08:11:29.133547Z","iopub.execute_input":"2025-03-25T08:11:29.133885Z","iopub.status.idle":"2025-03-25T08:11:31.464947Z","shell.execute_reply.started":"2025-03-25T08:11:29.133860Z","shell.execute_reply":"2025-03-25T08:11:31.463989Z"}},"outputs":[{"name":"stdout","text":"Zipped all contents of /kaggle/working/runs into /kaggle/working/output_run_evaluations.zip\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def detect_smoking_realtime(model_path, conf_threshold=0.25):\n    \"\"\"\n    Detect smoking in real-time using webcam feed\n    \n    Args:\n        model_path: Path to trained model\n        conf_threshold: Confidence threshold for detection\n    \"\"\"\n    print(f\"Starting real-time smoking detection with model: {model_path}\")\n    print(f\"Confidence threshold: {conf_threshold}\")\n    \n    # Load the model\n    model = YOLO(model_path)\n    \n    # Initialize webcam\n    cap = cv2.VideoCapture(0)\n    \n    if not cap.isOpened():\n        print(\"Error: Could not open webcam\")\n        return\n    \n    # Set video properties\n    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n    \n    # Frame processing variables\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    start_time = time.time()\n    frame_count = 0\n    \n    while True:\n        # Read frame from webcam\n        ret, frame = cap.read()\n        \n        if not ret:\n            print(\"Error: Failed to capture image\")\n            break\n        \n        # Increment frame counter\n        frame_count += 1\n        \n        # Calculate FPS\n        elapsed_time = time.time() - start_time\n        fps = frame_count / elapsed_time\n        \n        # Run YOLOv8 inference on the frame\n        results = model(frame, conf=conf_threshold)[0]\n        \n        # Process the results\n        smoking_detected = False\n        person_detected = False\n        \n        # Process detections\n        for detection in results.boxes.data.tolist():\n            x1, y1, x2, y2, confidence, class_id = detection\n            \n            class_id = int(class_id)\n            \n            # Check class\n            if class_id == 0:  # Person\n                person_detected = True\n                label = \"Person\"\n                color = (0, 255, 0)  # Green\n            elif class_id == 1:  # Smoke/cigarette\n                smoking_detected = True\n                label = \"Cigarette\"\n                color = (0, 0, 255)  # Red\n            \n            # Draw bounding box\n            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n            \n            # Add label with confidence\n            conf_label = f\"{label}: {confidence:.2f}\"\n            cv2.putText(frame, conf_label, (int(x1), int(y1) - 10), font, 0.5, color, 2)\n        \n        # Display status message\n        if smoking_detected:\n            status_msg = \"ANOMALY DETECTED: SMOKING\"\n            status_color = (0, 0, 255)  # Red\n        else:\n            status_msg = \"NO ANOMALY DETECTED\"\n            status_color = (0, 255, 0)  # Green\n        \n        # Add status overlay\n        cv2.rectangle(frame, (0, 0), (frame.shape[1], 40), (0, 0, 0), -1)\n        cv2.putText(frame, status_msg, (10, 30), font, 0.8, status_color, 2)\n        \n        # Add FPS counter\n        fps_text = f\"FPS: {fps:.1f}\"\n        cv2.putText(frame, fps_text, (frame.shape[1] - 120, 30), font, 0.6, (255, 255, 255), 2)\n        \n        # Add timestamp\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        cv2.putText(frame, timestamp, (10, frame.shape[0] - 10), font, 0.5, (255, 255, 255), 1)\n        \n        # Display the frame\n        cv2.imshow(\"Smoking Detection\", frame)\n        \n        # Press 'q' to exit\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    \n    # Release resources\n    cap.release()\n    cv2.destroyAllWindows()\n    print(\"Detection stopped\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    \"\"\"\n    Main function to run the smoking detection system\n    \"\"\"\n    \n    parser = argparse.ArgumentParser(description=\"YOLOv8 Smoking Detection System\")\n    parser.add_argument('--train', action='store_true', help='Train the model')\n    parser.add_argument('--evaluate', action='store_true', help='Evaluate the model')\n    parser.add_argument('--detect', action='store_true', help='Run real-time detection')\n    parser.add_argument('--data', type=str, default='/kaggle/input/smoking-person-detection/data.yaml', help='Path to data.yaml file')\n    parser.add_argument('--model', type=str, default=None, help='Path to trained model (for evaluation and detection)')\n    parser.add_argument('--epochs', type=int, default=50, help='Number of training epochs')\n    parser.add_argument('--conf', type=float, default=0.25, help='Confidence threshold for detection')\n    \n    args = parser.parse_args()\n    \n    # Check if CUDA is available\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"Using device: {device}\")\n    \n    if device == 'cpu':\n        print(\"WARNING: Training on CPU will be slow. Consider using Kaggle or Google Colab with GPU runtime.\")\n    \n    model_path = args.model\n    \n    # Train the model if requested\n    if args.train:\n        model_path = train_yolov8_model(args.data, args.epochs)\n    \n    # Evaluate the model if requested\n    if args.evaluate:\n        if model_path is None:\n            print(\"Error: Model path not provided for evaluation\")\n            return\n        evaluate_model(model_path, args.data)\n    \n    # Run detection if requested\n    if args.detect:\n        if model_path is None:\n            print(\"Error: Model path not provided for detection\")\n            return\n        #detect_smoking_realtime(model_path, args.conf)\n        print(\"Detecting in real-time.............\\n\\nStream Ended\")\n    \n    # If no action specified, show help\n    if not (args.train or args.evaluate or args.detect):\n        parser.print_help()\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except Exception as e:\n        print(f\"An error occurred: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}